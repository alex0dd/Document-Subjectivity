{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Document-Subjectivity-Experiment-1",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ12kxS5ZK3D"
      },
      "source": [
        "Experiment 1\n",
        "\n",
        "Perform document classification based on document embeddings. Document embeddings can be computed by some sentence embedder model and aggregated together by some aggregation procedure (e.g. mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNvVyxgEa56v"
      },
      "source": [
        "# Prepare environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW4ai4Yea8Fi"
      },
      "source": [
        "!git clone https://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:x-oauth-basic@github.com/alexpod1000/Document-Subjectivity.git\n",
        "%cd Document-Subjectivity/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gvjT0dpLCQW"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP4ne673awgC"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNyz0em8ao7M"
      },
      "source": [
        "!git clone https://github.com/francescoantici/SubjectivITA.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayuHthdvcdCc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKooIldVVIq1"
      },
      "source": [
        "sentence_embedder_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5kuP2Ca3Xzi"
      },
      "source": [
        "def get_sentences(split):\n",
        "    to_keep = [\"ID_ARTICOLO\", \"ID_FRASE\", \"FRASE\", \"TAG_FRASE\", \"TAG_ARTICOLO\", \"FONTE\"]\n",
        "    tag_mapper = {\"SOG\": 0, \"OGG\": 1}\n",
        "    df = pd.read_csv(\"SubjectivITA/datasets/sentences/sentences{}.csv\".format(split.capitalize()))\n",
        "    df[\"TAG_FRASE\"] = df[\"TAG_FRASE\"].replace(tag_mapper)\n",
        "    df[\"TAG_ARTICOLO\"] = df[\"TAG_ARTICOLO\"].replace(tag_mapper)\n",
        "    # TODO(alexo): check better if different splits have overlapping ids for different FONTE field\n",
        "    df[\"FONTE\"] = df[\"FONTE\"].astype('category').cat.codes\n",
        "    return df[to_keep]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZyGjPwDPR0"
      },
      "source": [
        "def load_split_ids(split):\n",
        "    df_articles = pd.read_csv(\"SubjectivITA/datasets/articles/articles{}.csv\".format(split.capitalize()))\n",
        "    df_articles[\"ID_ARTICOLO\"] = df_articles[\"ID_ARTICOLO\"].astype(np.int32)\n",
        "    return df_articles[\"ID_ARTICOLO\"].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxqJ5WK4DGux"
      },
      "source": [
        "articles_ids_train = load_split_ids(\"train\")\n",
        "articles_ids_test = load_split_ids(\"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsugc53VE9hU"
      },
      "source": [
        "def build_articles_embeddings_data(df, model, aggr_fn = partial(np.mean, axis=0)):\n",
        "    sentences_list = df[\"FRASE\"].tolist()\n",
        "    df[\"EMB_FRASE\"] = model.encode(sentences_list, convert_to_tensor=True).cpu().numpy().tolist()\n",
        "    articles_dataset = {}\n",
        "    # Divide articles by groups\n",
        "    article_groups = df.groupby(['ID_ARTICOLO'])\n",
        "    for article_group in article_groups:\n",
        "        article_id = article_group[0]\n",
        "        df_by_article_id = article_group[1]\n",
        "        sentence_embeddings = np.array(df_by_article_id[\"EMB_FRASE\"].tolist())\n",
        "        # Get embeddings for a single document (from sentence embeddings)\n",
        "        document_embedding = aggr_fn(sentence_embeddings)\n",
        "        articles_dataset[article_id] = {\"document_emb\": document_embedding, \"article_tag\": df_by_article_id[\"TAG_ARTICOLO\"].tolist()[0]}\n",
        "    articles_df = pd.DataFrame(articles_dataset).T\n",
        "    # convert to numpy\n",
        "    X = np.array(articles_df[\"document_emb\"].tolist(), dtype=np.float32)\n",
        "    y = np.array(articles_df[\"article_tag\"], dtype=np.float32)\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JntbWoeG_ZA"
      },
      "source": [
        "df_train = get_sentences(\"train\")\n",
        "df_val = get_sentences(\"val\")\n",
        "df_test = get_sentences(\"test\")\n",
        "# combine all the splits into a single dataframe\n",
        "df_all = pd.concat([df_train, df_val, df_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU-hfQaDFMX0"
      },
      "source": [
        "# redistribute data according to articles splits\n",
        "df_train = df_all.query('ID_ARTICOLO in @articles_ids_train')\n",
        "df_test = df_all.query('ID_ARTICOLO in @articles_ids_test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVxXKhrjGISX"
      },
      "source": [
        "aggr_fn = partial(np.mean, axis=0)\n",
        "X_train, y_train = build_articles_embeddings_data(df_train, sentence_embedder_model, aggr_fn=aggr_fn)\n",
        "X_test, y_test = build_articles_embeddings_data(df_test, sentence_embedder_model,  aggr_fn=aggr_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzMmIZupHKOU"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7f6DN-YEhOY"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "weights = compute_class_weight(class_weight = 'balanced', classes = [0.0, 1.0], y = y_train)\n",
        "class_weights = {0 : weights[0], 1: weights[1]}    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "107kcKJZIBTH"
      },
      "source": [
        "class_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brJlQ54mEbIa"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "classifier_models_list = {\n",
        "    \"svm\": LinearSVC(class_weight=class_weights),\n",
        "    \"logistic\": LogisticRegression(class_weight=class_weights),\n",
        "    \"random-forest\": RandomForestClassifier(),\n",
        "    #\"naive-bayes\": MultinomialNB(),\n",
        "    \"decision-tree\": DecisionTreeClassifier()\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Vz3vpRXasS"
      },
      "source": [
        "for model_name, classifier_model in classifier_models_list.items():\n",
        "    print(f\"Fitting model {model_name}\")\n",
        "    classifier_model.fit(X_train, y_train)\n",
        "    print(classification_report(y_test, classifier_model.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}